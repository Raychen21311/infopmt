# -*- coding: utf-8 -*-
"""
final_optional.py â€” RFP/å¥‘ç´„ å¯©æŸ¥ï¼ˆè³‡è¨Šè™•æª¢æ ¸ç‰ˆï¼‰
æ–°å¢ï¼šæª¢æ ¸æ¨¡å¼ä¸‰é¸ä¸€ï¼š
- å¿«ï¼šABCDE å…¨éƒ¨ä¸€èµ·ï¼ˆæœ€å¿«ï¼Œä½†è¼ƒç°¡ç•¥ï¼‰
- ä¸­ï¼šAB ä¸€èµ·ã€CDE ä¸€èµ·ï¼ˆä¸­ç­‰ï¼‰
- æ…¢ï¼šé€é¡Œæª¢æ ¸ï¼ˆæœ€æ…¢ä½†æœ€ç²¾ç´°ï¼‰
"""
import os, re, json, io
from typing import List, Dict, Any, Tuple
import streamlit as st
import fitz  # PyMuPDF
import pandas as pd
from dotenv import load_dotenv
import google.generativeai as genai

# ---------------- LLM ----------------
load_dotenv()
if os.getenv('GOOGLE_API_KEY'):
    genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
model = genai.GenerativeModel("gemini-2.5-flash")

# ---------------- æª¢æ ¸æ¸…å–® ----------------
def build_rfp_checklist() -> List[Dict[str, Any]]:
    items: List[Dict[str, Any]] = []
    def add(cat, code, text): items.append({"category":cat, "id":code, "item":text})
    # A
    add("A åŸºæœ¬èˆ‡å‰æ¡ˆ", "A0", "æœ¬æ¡ˆå±¬é–‹ç™¼å»ºç½®ã€ç³»çµ±ç¶­é‹ã€åŠŸèƒ½å¢ä¿®ã€å¥—è£è»Ÿé«”ã€ç¡¬é«”ã€å…¶ä»–?")
    add("A åŸºæœ¬èˆ‡å‰æ¡ˆ", "A1", "æœ¬æ¡ˆç‚ºå»¶çºŒæ€§åˆç´„ï¼Œå‰æ¡ˆæ¡è³¼ç°½é™³å½±æœ¬å·²é™„ã€‚")
    add("A åŸºæœ¬èˆ‡å‰æ¡ˆ", "A2.1", "æœ¬æ¡ˆäº‹å‰æ›¾èˆ‡è³‡è¨Šè™•è¨è«–ï¼šæœ¬æ¡ˆç›¸é—œæŠ€è¡“æ–‡ä»¶ç”±è³‡è¨Šè™•å”åŠ©æ’°å¯«ã€‚")
    add("A åŸºæœ¬èˆ‡å‰æ¡ˆ", "A2.2", "æœ¬æ¡ˆäº‹å‰æ›¾èˆ‡è³‡è¨Šè™•è¨è«–ï¼šè¦åŠƒéšæ®µæ›¾èˆ‡è³‡è¨Šè™•é–‹æœƒè¨è«–æ¡è³¼å…§å®¹ä¸¦æœ‰æœƒè­°ç´€éŒ„ã€‚")
    add("A åŸºæœ¬èˆ‡å‰æ¡ˆ", "A2.3", "æœ¬æ¡ˆç°½è¾¦ä¹‹å‰ï¼Œå·²ä»¥è«‹è¾¦å–®éäº¤å¥‘ç´„æ›¸ã€éœ€æ±‚èªªæ˜æ›¸ç­‰ç›¸é—œæ–‡ä»¶ï¼Œé€è«‹è³‡è¨Šè™•æª¢è¦–ï¼Œä¸¦ä¿ç•™è‡³å°‘5å€‹å·¥ä½œå¤©ä¹‹å¯©é–±æœŸå¾Œå–å¾—å›è¦†ã€‚")
    add("A åŸºæœ¬èˆ‡å‰æ¡ˆ", "A2.4", "æœ¬æ¡ˆäº‹å‰æœªèˆ‡è³‡è¨Šè™•è¨è«–ï¼ˆç„¡ï¼‰ã€‚")
    # B
    add("B ç¾æ³èªªæ˜", "B1.1", "æä¾›æœ€æ–°ç‰ˆç¡¬é«”è¨­å‚™åŠç¶²è·¯ä¹‹æ¶æ§‹åœ–(ä¸å«IP Address)ï¼šæ˜ç¢ºè¡¨é”ç¡¬é«”æ”¾ç½®å€åŸŸï¼ˆå«æ©Ÿæˆ¿/å€åŸŸï¼‰ã€‚")
    add("B ç¾æ³èªªæ˜", "B1.2", "æä¾›ç¶²è·¯ä»‹æ¥æ–¹å¼èˆ‡é–‹ç™¼å·¥å…·ä¹‹å» ç‰Œã€å‹è™Ÿã€ç‰ˆæœ¬ç­‰è³‡è¨Šã€‚")
    add("B ç¾æ³èªªæ˜", "B2", "ç½®æ–¼æœ¬éƒ¨æ©Ÿæˆ¿ä¹‹ç³»çµ±ï¼Œå¦‚å¦è¨­å°å¤–é€£ç·šç·šè·¯è€…ï¼Œæä¾›é€£ç·šå°è±¡ã€ç¨®é¡åŠè¦æ ¼æ¸…å–®ã€‚")
    add("B ç¾æ³èªªæ˜", "B3", "æä¾›ä½¿ç”¨è€…æˆ–ä½¿ç”¨æ©Ÿé—œä¹‹ç¤ºæ„åœ–æˆ–èªªæ˜ã€‚")
    add("B ç¾æ³èªªæ˜", "B4", "æä¾›æœ€æ–°ç¶²ç«™ç¶²å€ã€‚")
    add("B ç¾æ³èªªæ˜", "B5", "æä¾›æ‡‰ç”¨ç³»çµ±åŠŸèƒ½æ¸…å–®æˆ–æ¶æ§‹åœ–ï¼ˆå« OSã€DB åç¨±èˆ‡ç‰ˆæœ¬ï¼‰ã€‚")
    # C
    add("C è³‡å®‰éœ€æ±‚", "C1.1", "ç¬¦åˆæœ¬éƒ¨æ¡è³¼å¥‘ç´„è¦ç¯„ä¹‹è³‡è¨Šå®‰å…¨èˆ‡å€‹è³‡ä¿è­·è¦æ±‚ï¼šå·²å¡«åˆ—å®‰å…¨ç­‰ç´šä¸”èˆ‡æœ€æ–°æ ¸å®šç­‰ç´šç›¸ç¬¦ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C1.2", "è¦æ±‚ç³»çµ±ç¬¦åˆã€Šè³‡é€šå®‰å…¨è²¬ä»»ç­‰ç´šåˆ†ç´šè¾¦æ³•ã€‹ä¹‹ã€è³‡é€šç³»çµ±é˜²è­·åŸºæº–ã€ã€SSDLC å„éšæ®µå®‰å…¨å·¥ä½œï¼›è¦æ±‚å» å•†æäº¤ã€è³‡é€šç³»çµ±é˜²è­·åŸºæº–è‡ªè©•è¡¨ã€ä¸¦å¢åˆ—ç½°å‰‡ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C1.3", "è¦æ±‚å» å•†ä¹‹æœå‹™æ°´æº–æ»¿è¶³ç³»çµ±æœ€å¤§å¯å®¹å¿ä¸­æ–·æ™‚é–“ï¼ˆRTOï¼‰ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C1.4", "éç½®æ–¼æœ¬éƒ¨æ©Ÿæˆ¿ä¹‹æ ¸å¿ƒè³‡é€šç³»çµ±ï¼Œç´å…¥ SOC ç¯„åœã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C1.5", "å§”å¤–éœ€æ±‚æ¶‰åŠè³‡é€šæŠ€è¡“æœå‹™ï¼ˆå¦‚é›²ç«¯ï¼‰å·²è©•ä¼°åˆæ³•æ€§ã€æŠ€è¡“ç¶­é‹ã€æ³•éµèˆ‡æ¬Šåˆ©ç¾©å‹™æ­¸å±¬ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C1.6", "è¦æ±‚å» å•†ä¸å¾—ä½¿ç”¨æˆ–è¨­è¨ˆä¸ç¬¦å®‰å…¨è¦ç¯„ä¹‹å¸³è™Ÿå¯†ç¢¼ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C2.1", "å·¨é¡/è³‡å®‰æ¡è³¼æˆ–é«˜ç´šå®‰å…¨ç­‰ç´šæ¡ˆä»¶ï¼šæŠ•æ¨™å» å•†å…·å‚™å®‰å…¨è»Ÿé«”é–‹ç™¼èƒ½åŠ›ä¸¦é€šéè³‡å®‰ç®¡ç†ç³»çµ±é©—è­‰ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C2.2", "å·¨é¡/è³‡å®‰/é«˜ç´šï¼šå°ˆæ¡ˆç®¡ç†äººå“¡è‡³å°‘1äººå…·è³‡è¨Šå®‰å…¨å°ˆæ¥­èªè­‰ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C2.3", "å·¨é¡/è³‡å®‰/é«˜ç´šï¼šå°ˆæ¡ˆæŠ€è¡“äººå“¡è‡³å°‘1äººå…·ç¶²è·¯å®‰å…¨æŠ€èƒ½ä¹‹è¨“ç·´è­‰æ›¸æˆ–è­‰ç…§ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C3.1", "å…è¨±åˆ†åŒ…è€…ï¼šåˆ†åŒ…å» å•†é ˆæ¯”ç…§æ‰¿åŒ…å» å•†å…±åŒéµå®ˆè³‡å®‰è¦å®šã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C3.2", "å…è¨±åˆ†åŒ…è€…ï¼šæŠ•æ¨™å» å•†æ–¼å»ºè­°æ›¸æ•˜æ˜åˆ†åŒ…å» å•†åŸºæœ¬è³‡æ–™ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C4", "ä¸å¾—æ¡ç”¨å¤§é™¸å» ç‰Œè³‡é€šè¨Šç”¢å“ï¼ˆå¥‘ç´„è‰æ¡ˆç¬¬å…«æ¢(å…­)åŠ(äºŒ äº”)ï¼‰ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C5", "ç¬¦åˆã€è³‡é€šç³»çµ±ç±Œç²å„éšæ®µè³‡å®‰å¼·åŒ–æªæ–½åŸ·è¡Œæª¢æ ¸è¡¨ã€ï¼ˆé–‹ç™¼é™„è¡¨1/ç¶­é‹é™„è¡¨2ï¼‰ã€‚")
    add("C è³‡å®‰éœ€æ±‚", "C6", "è³‡æ–™åº«ä¸­æ©Ÿæ•è³‡æ–™å·²æ¡ç”¨æˆ–è¦åŠƒé©ç•¶åŠ å¯†æŠ€è¡“ã€‚")
    # Dï¼ˆç¯€éŒ„ï¼‰
    add("D ä½œæ¥­éœ€æ±‚", "D1", "åˆ—å‡ºæ‰€éœ€è»Ÿç¡¬é«”èˆ‡ç¶²è·¯è¨­å‚™æ¸…å–®ï¼Œèªªæ˜ä½¿ç”¨è³‡è¨Šè™•è¨­å‚™/æ—¢æœ‰è¨­å‚™æˆ–å¦è¡Œæ¡è³¼ï¼ˆå„ªå…ˆ VM/å…±åŒä¾›æ‡‰å¥‘ç´„ï¼‰ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D2", "ç³»çµ±é–‹ç™¼æˆ–åŠŸèƒ½å¢ä¿®æ‡‰åˆ—å‡ºæ‰€éœ€ç³»çµ±åŠŸèƒ½ï¼ˆåœ°æ–¹æ”¿åºœç³»çµ±å»ºè­°æä¾›è³‡æ–™ä¸‹è¼‰æˆ–ä»‹æ¥ï¼‰ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D3", "æ•˜æ˜è³‡è¨Šç³»çµ±èˆ‡å…¶ä»–è»Ÿé«”ç³»çµ±ä¹‹ç›¸äº’é—œä¿‚ä¸¦èªªæ˜æ‰€æœ‰åˆ©å®³é—œä¿‚äººã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D4", "æä¾›æ°‘çœ¾ä¸‹è¼‰æª”æ¡ˆè€…ï¼Œå¢åŠ  ODF æ ¼å¼ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D5", "é–‹ç™¼ App å·²é–±è®€ä¸¦éµå¾ªåœ‹ç™¼æœƒç›¸é—œè¦å®šï¼ˆé™„ä»¶2ï¼‰ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D6", "é–‹ç™¼ App ç¬¦åˆé€šå‚³æœƒã€App ç„¡éšœç¤™é–‹ç™¼æŒ‡å¼•ã€ä¸¦å¡«å ±æª¢æ ¸è¡¨ï¼ˆé™„ä»¶3ï¼‰ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D7", "ç¶²ç«™æœå‹™ä¹‹ç³»çµ±ç¬¦åˆåœ‹ç™¼æœƒã€æ”¿åºœç¶²ç«™æœå‹™ç®¡ç†è¦ç¯„ã€ä¸¦å¡«å ±æª¢æ ¸è¡¨ï¼ˆé™„ä»¶4ï¼‰ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D8", "é‡å°æ¥­å‹™æˆ–å€‹äººè³‡æ–™ï¼Œæä¾›å¾ŒçºŒ OpenData æˆ– MyData æœå‹™å»ºè­°ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D9", "ç³»çµ±ç¶­è­·åŒ…å«å®šæœŸåˆ°å ´ã€ç·Šæ€¥åˆ°å ´ã€è«®è©¢æœå‹™ï¼›SLA èˆ‡ç¸¾æ•ˆæŒ‡æ¨™é€£å‹•ä¸¦è¨­è¨ˆæ»¿æ„åº¦èª¿æŸ¥ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D10", "å±¥ç´„æœå‹™éŠœæ¥å¥‘ç´„æœŸé–“ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D11", "é–‹ç™¼åŠæ¸¬è©¦è¨­å‚™èˆ‡ç’°å¢ƒéœ€æ±‚èªªæ˜ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D12", "æ•™è‚²è¨“ç·´åŠå®¢æœæœå‹™ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D13", "ä¿å›ºæœå‹™ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D14", "ç”¢å“æˆæ¬Š (License) ç¬¦åˆéœ€æ±‚ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D15", "ä½œæ¥­éœ€æ±‚å¿…é ˆç´å…¥ä¹‹åˆ¶å¼æ–‡å¥ï¼ˆè©³è¨»5ï¼‰ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D16", "å¦‚æœ‰ GIS / OpenData / MyData ä½œæ¥­éœ€æ±‚ï¼Œç´å…¥ä¹‹åˆ¶å¼æ–‡å¥ï¼ˆè©³è¨»6ï¼‰ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D17", "ä¸Šç·šå‰å®Œæˆéœ€æ±‚è¨ªè«‡ã€éœ€æ±‚ç¢ºèªèˆ‡æ¸¬è©¦ï¼ˆå«æ•ˆèƒ½æ¸¬è©¦ï¼‰ï¼›æäº¤æ¸¬è©¦è¨ˆç•«èˆ‡æ¸¬è©¦å ±å‘Šã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D18", "æ¶‰åŠé†«ç™‚/å¥åº·è³‡æ–™äº¤æ›è€…ï¼Œç´å…¥ FHIR äº¤æ›æ¨™æº–ã€‚")
    add("D ä½œæ¥­éœ€æ±‚", "D19", "åŠŸèƒ½éœ€æ±‚è¨­è¨ˆè€ƒé‡å°å…¥ AI ä»¥ç¯€çœäººåŠ›/é¿å…éŒ¯èª¤èˆ‡æ±ºç­–åˆ†æåŠé¢¨éšªé è­¦ã€‚")
    # E
    add("E ç”¢å“äº¤ä»˜", "E1", "äº¤ä»˜æ™‚ç¨‹åˆç†ï¼Œä¸¦èˆ‡é–‹ç™¼æ–¹å¼ï¼ˆç€‘å¸ƒ/æ•æ·ï¼‰ä¸€è‡´ã€‚")
    add("E ç”¢å“äº¤ä»˜", "E2", "é–‹ç™¼/å¢ä¿®äº¤ä»˜å“å®Œæ•´ï¼ˆå°ˆæ¡ˆè¨ˆç•«ã€éœ€æ±‚/è¨­è¨ˆã€æ¸¬è©¦è¨ˆç•«/å ±å‘Šã€å»ºç½®è¨ˆç•«ã€æ‰‹å†Šã€æ•™è‚²è¨“ç·´ã€ä¿å›ºç´€éŒ„ã€åŸå§‹ç¢¼/åŸ·è¡Œç¢¼ã€æœ€é«˜æ¬Šé™å¸³å¯†ã€è‡ªè©•è¡¨èˆ‡é›»å­æª”ï¼‰ã€‚")
    add("E ç”¢å“äº¤ä»˜", "E3", "ç¶­è­·äº¤ä»˜å“ï¼ˆå°ˆæ¡ˆåŸ·è¡Œè¨ˆç•«ã€ç¶­è­·å·¥ä½œå ±å‘Šã€æœ€æ–°ç‰ˆè¨­è¨ˆ/æ‰‹å†Šã€æœ€æ–°ç‰ˆåŸå§‹ç¢¼/åŸ·è¡Œç¢¼ã€è‡ªè©•è¡¨èˆ‡é›»å­æª”ï¼‰ã€‚")
    add("E ç”¢å“äº¤ä»˜", "E4", "å¿…é ˆç´å…¥ä¹‹åˆ¶å¼æ–‡å¥ï¼ˆè©³è¨»8ï¼‰ï¼šäº¤ä»˜ä¹‹åŸå§‹ç¨‹å¼ç¢¼ã€åŸ·è¡Œç¢¼ï¼Œæœ¬éƒ¨å¾—è¦æ±‚æ‰¿åŒ…å» å•†æ–¼æœ¬éƒ¨æŒ‡å®šä¹‹ç’°å¢ƒé€²è¡Œå†ç”Ÿæ¸¬è©¦ï¼Œä¸¦æ‡‰æä¾›æ‰€ä½¿ç”¨ä¹‹é–‹ç™¼å·¥å…·ï¼Œä»¥é©—è­‰å…¶æ­£ç¢ºæ€§ã€‚")
    add("E ç”¢å“äº¤ä»˜", "E5", "ç¶²è·¯è¨­å‚™è³¼ç½®æ™‚ï¼Œé©—æ”¶ä»¥å½Œå°æ–¹å¼äº¤ä»˜å¸³å¯†ã€è¨­å®šæª”ã€è¦å‰‡åˆ—è¡¨èˆ‡æ¶æ§‹ç­‰ã€‚")
    return items

# ---------------- åˆ†ç¾¤å·¥å…· ----------------
def group_items_by_ABCDE(items: List[Dict[str, Any]]) -> List[Tuple[str, List[Dict[str, Any]]]]:
    return [("ABCDE", items)] if items else []

def group_items_by_AB_CDE(items: List[Dict[str, Any]]) -> List[Tuple[str, List[Dict[str, Any]]]]:
    ab  = [it for it in items if it['id'] and it['id'][0] in ('A','B')]
    cde = [it for it in items if it['id'] and it['id'][0] in ('C','D','E')]
    groups = []
    if ab:  groups.append(('AB', ab))
    if cde: groups.append(('CDE', cde))
    return groups

def group_items_by_AB_C_D_E(items: List[Dict[str, Any]]) -> List[Tuple[str, List[Dict[str, Any]]]]:
    ab = [it for it in items if it['id'] and it['id'][0] in ('A','B')]
    c  = [it for it in items if it['id'] and it['id'][0] == 'C']
    d  = [it for it in items if it['id'] and it['id'][0] == 'D']
    e  = [it for it in items if it['id'] and it['id'][0] == 'E']
    groups = []
    if ab: groups.append(('AB', ab))
    if c:  groups.append(('C', c))
    if d:  groups.append(('D', d))
    if e:  groups.append(('E', e))
    return groups

# é€é¡Œæ’åºï¼ˆABâ†’Câ†’Dâ†’Eï¼‰
def order_items_AB_C_D_E(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    order_map = {'A':0,'B':1,'C':2,'D':3,'E':4}
    return sorted(items, key=lambda it: (order_map.get(it['id'][0], 9), it['id']))

# ---------------- PDF è§£æ ----------------
def extract_text_with_headers(pdf_bytes: bytes, filename: str) -> str:
    doc = fitz.open(stream=pdf_bytes, filetype='pdf')
    parts = []
    for i, page in enumerate(doc, start=1):
        text = page.get_text('text').strip()
        if not text:
            blocks = page.get_text('blocks')
            text = "\n\n".join([b[4].strip() for b in blocks if b[4].strip()])
        parts.append(f"\n\n===== ã€æª”æ¡ˆ: {filename} | é : {i}ã€‘ =====\n" + text)
    return "\n".join(parts)

# ---------------- Prompts ----------------
def make_batch_prompt(batch_code: str, items: List[Dict[str, Any]], corpus_text: str) -> str:
    checklist_lines = "\n".join([f"{it['id']}ï½œ{it['item']}" for it in items])
    return f"""
ä½ æ˜¯æ”¿åºœæ©Ÿé—œè³‡è¨Šè™•ä¹‹æ¡è³¼/RFP/å¥‘ç´„å¯©æŸ¥å§”å“¡ã€‚è«‹ä¾ä¸‹åˆ—ã€Œæª¢æ ¸æ¢ç›®ï¼ˆ{batch_code} æ‰¹ï¼‰ã€é€æ¢å¯©æŸ¥æ–‡ä»¶å…§å®¹ä¸¦å›å‚³**å”¯ä¸€ JSON é™£åˆ—**ï¼Œé™£åˆ—å…§æ¯å€‹å…ƒç´ å°æ‡‰ä¸€æ¢æ¢ç›®ã€‚
ã€å¯©æŸ¥åŸå‰‡ã€‘
1) åƒ…ä¾æ–‡ä»¶æ˜è¼‰å…§å®¹åˆ¤æ–·ï¼›æœªæåŠå³æ¨™ç¤ºã€ŒæœªæåŠã€ã€‚
2) è‹¥å±¬ä¸é©ç”¨ï¼ˆä¾‹ï¼šæœªå…è¨±åˆ†åŒ…ï¼‰ï¼Œè«‹å›ã€Œä¸é©ç”¨ã€ä¸¦èªªæ˜ä¾æ“šã€‚
3) å‹™å¿…å¼•ç”¨åŸæ–‡çŸ­å¥èˆ‡æª”å/é ç¢¼ä½œç‚º evidenceã€‚
4) ***åš´ç¦è¼¸å‡ºä»»ä½•èˆ‡è¦æ ¼è¯çµ¡äººã€é›»è©±ã€å§“åã€è¯ç¹«æ–¹å¼æœ‰é—œçš„æ–‡å­—ï¼Œå³ä½¿åŸå§‹æ–‡ä»¶å…§æœ‰ã€‚*******

ã€è¼¸å‡ºæ ¼å¼ â€” åƒ…èƒ½è¼¸å‡º JSON é™£åˆ—ï¼Œç„¡ä»»ä½•å¤šé¤˜æ–‡å­—/æ¨™è¨˜ã€‘
[
  {{
    "id": "A1",
    "category": "A åŸºæœ¬èˆ‡å‰æ¡ˆ",
    "item": "æ¢ç›®åŸæ–‡ï¼ˆè«‹å®Œæ•´è¤‡è£½ï¼‰",
    "compliance": ""compliance": "è‹¥ id = 'A0'ï¼šåƒ…èƒ½è¼¸å‡ºå…­é¸ä¸€ã€é–‹ç™¼å»ºç½®ï½œç³»çµ±ç¶­é‹ï½œåŠŸèƒ½å¢ä¿®ï½œå¥—è£è»Ÿé«”ï½œç¡¬é«”ï½œå…¶ä»–ã€‘ï¼›è‹¥ id â‰  'A0'ï¼šåƒ…èƒ½è¼¸å‡ºå››é¸ä¸€ã€ç¬¦åˆï½œéƒ¨åˆ†ç¬¦åˆï½œæœªæåŠï½œä¸é©ç”¨ã€‘ï¼›ç¦æ­¢åŒæ™‚è¼¸å‡ºå¤šå€‹æˆ–å…¶ä»–æ–‡å­—"
",
    "evidence": [{{"file": "æª”å", "page": é ç¢¼, "quote": "é€å­—å¼•è¿°"}}],
    "recommendation": "è‹¥æœªæåŠ/éƒ¨åˆ†ç¬¦åˆï¼Œè«‹çµ¦å…·é«”è£œå¼·æ–¹å‘ï¼›å¦å‰‡ç•™ç©º"
  }}
]
ã€æœ¬æ‰¹æª¢æ ¸æ¸…å–®ï¼ˆidï½œitemï¼‰ã€‘
{checklist_lines}
ã€æ–‡ä»¶å…¨æ–‡ï¼ˆå«æª”å/é ç¢¼æ¨™è¨»ï¼‰ã€‘
{corpus_text}
"""

def make_single_prompt(item: Dict[str, Any], corpus_text: str) -> str:
    return make_batch_prompt(item['id'], [item], corpus_text)

# ---------------- è§£æ ----------------
def parse_json_array(text: str) -> List[Dict[str, Any]]:
    t = text.strip()
    t = re.sub(r'^```(?:json)?', '', t, flags=re.I).strip()
    t = re.sub(r'```$', '', t, flags=re.I).strip()
    if t.startswith('{') and t.endswith('}'):
        try:
            d = json.loads(t)
            return [d]
        except Exception:
            pass
    start = t.find('[')
    end = t.rfind(']')
    if start != -1 and end != -1 and end > start:
        t = t[start:end+1]
    data = json.loads(t)
    if isinstance(data, dict):
        data = [data]
    return data

# ---------------- å ±è¡¨ ----------------
def to_dataframe(results: List[Dict[str, Any]]) -> pd.DataFrame:
    rows = []
    for r in results:
        ev_text = "\n".join([f"{e.get('file','')} p.{e.get('page','')}ï¼š{e.get('quote','')}" for e in r.get('evidence', [])])
        rows.append({
            "é¡åˆ¥": r.get("category",""),
            "ç·¨è™Ÿ": r.get("id",""),
            "æª¢æ ¸é …ç›®": r.get("item",""),
            "ç¬¦åˆæƒ…å½¢": r.get("compliance",""),
            "ä¸»è¦è­‰æ“š": ev_text,
            "æ”¹å–„å»ºè­°": r.get("recommendation",""),
        })
    df = pd.DataFrame(rows)
    try:
        df["ä¸»ç¢¼"] = df["ç·¨è™Ÿ"].str.extract(r"([A-Z])")
        df["å­ç¢¼å€¼"] = pd.to_numeric(df["ç·¨è™Ÿ"].str.extract(r"(\d+(?:\.\d+)?)")[0], errors='coerce')
        df = df.sort_values(["ä¸»ç¢¼","å­ç¢¼å€¼"], kind='mergesort').drop(columns=["ä¸»ç¢¼","å­ç¢¼å€¼"])
    except Exception:
        pass
    return df

# ---------------- è¡¨æ ¼ ----------------
def render_wrapped_table(df: pd.DataFrame, height_vh: int = 80):
    df2 = df.copy()
    for c in df2.columns:
        df2[c] = df2[c].astype(str).str.replace('\n','<br>')
    style = f"""
    <style>
    .wrap-table-container {{max-height:{height_vh}vh; overflow:auto; border:1px solid #e5e7eb; border-radius:8px;}}
    .wrap-table-container table {{width:100%; border-collapse:collapse; table-layout:fixed; font-size:14px;}}
    .wrap-table-container th, .wrap-table-container td {{border:1px solid #efefef; padding:6px 10px; text-align:left; vertical-align:top; white-space:pre-wrap; word-break:break-word;}}
    .wrap-table-container thead th {{position:sticky; top:0; background:#fafafa; z-index:1;}}
    </style>
    """
    st.markdown(style, unsafe_allow_html=True)
    html = df2.to_html(index=False, escape=False)
    st.markdown(f'<div class="wrap-table-container">{html}</div>', unsafe_allow_html=True)

# ---------------- ä¸»ç¨‹å¼ï¼ˆä¸‰ç¨®æ¨¡å¼ï¼‰ ----------------
def main():
    st.set_page_config("ğŸ“‘ RFP/å¥‘ç´„å¯©æŸ¥ç³»çµ±", layout="wide")
    st.title("ğŸ“‘ è³‡è¨Šæœå‹™æ¡è³¼ RFP/å¥‘ç´„å¯©æŸ¥ç³»çµ±")

    uploaded_files = st.file_uploader("ğŸ“¥ ä¸Šå‚³ RFP/å¥‘ç´„ PDFï¼ˆå¯è¤‡é¸ï¼‰", type=["pdf"], accept_multiple_files=True)
    project_name = st.text_input("æ¡ˆä»¶/å°ˆæ¡ˆåç¨±ï¼ˆå°‡ç”¨æ–¼æª”åï¼‰", value="æœªå‘½åæ¡ˆä»¶")
    
    mode = st.radio(
        "æª¢æ ¸æ¨¡å¼",
        (
            "ä¸€æ¬¡æ€§å¯©æŸ¥",
            "æ‰¹æ¬¡å¯©æŸ¥",
            "é€é¡Œå¯©æŸ¥",
        ),
        horizontal=True,
    )

    if st.button("ğŸš€ é–‹å§‹å¯©æŸ¥", disabled=not uploaded_files):
        checklist_all = build_rfp_checklist()

        # é€²åº¦æ¢è¨­å®š
        progress_text = st.empty(); progress_bar = st.progress(0)
        def set_progress(p, msg):
            progress_bar.progress(max(0, min(int(p), 100))); progress_text.write(msg)

        # 1) è§£æ PDFï¼ˆè‡³ 35%ï¼‰
        set_progress(5, "ğŸ“„ è§£æèˆ‡å½™æ•´æ–‡ä»¶æ–‡å­—â€¦")
        corpora = []; total_files = len(uploaded_files)
        for i, f in enumerate(uploaded_files):
            set_progress(int((i/ max(1,total_files))*30), f"ğŸ“„ è§£æ {f.name} ({i+1}/{total_files})â€¦")
            pdf_bytes = f.read(); text = extract_text_with_headers(pdf_bytes, f.name)
            corpora.append(text)
        corpus_text = "\n\n".join(corpora)
        set_progress(35, "ğŸ§© æª¢æ ¸æº–å‚™ä¸­â€¦")

        all_results: List[Dict[str, Any]] = []

        if mode.startswith("ä¸€"):
            # ---- å…¨éƒ¨ä¸€èµ·ï¼ˆ1 æ‰¹ï¼‰ ----
            groups = group_items_by_ABCDE(checklist_all)
            st.info("ä¸€æ¬¡æ€§å¯©æŸ¥ä¸­")
        elif mode.startswith("æ‰¹"):
            # ---- å…©æ‰¹ï¼šAB + CDE ----
            groups = group_items_by_AB_CDE(checklist_all)
            st.info("æ‰¹æ¬¡å¯©æŸ¥ä¸­")
        else:
            groups = None  # é€é¡Œæ¨¡å¼ä¸ç”¨ groups

        if groups is not None:
            # æ‰¹æ¬¡æ¨¡å¼ï¼ˆå¿« or ä¸­ï¼‰
            total_batches = len(groups)
            for bi, (code, items) in enumerate(groups):
                set_progress(35 + int((bi/ max(1,total_batches))*55), f"ğŸ” ç¬¬ {bi+1}/{total_batches} æ‰¹ï¼ˆ{code}ï¼‰â€¦ å…± {len(items)} é …")
                prompt = make_batch_prompt(code, items, corpus_text)
                try:
                    resp = model.generate_content(prompt)
                    arr = parse_json_array(resp.text)
                except Exception:
                    arr = []
                allowed_ids = {it['id'] for it in items}
                id_to_meta = {it['id']: it for it in items}
                normalized = []
                for d in arr if isinstance(arr, list) else []:
                    if not isinstance(d, dict):
                        continue
                    rid = d.get('id')
                    if rid not in allowed_ids:
                        continue
                    meta = id_to_meta[rid]
                    normalized.append({
                        'id': rid,
                        'category': d.get('category', meta['category']),
                        'item': d.get('item', meta['item']),
                        'compliance': d.get('compliance', ''),
                        'evidence': d.get('evidence', []),
                        'recommendation': d.get('recommendation', ''),
                    })
                returned_ids = {x['id'] for x in normalized}
                for it in items:
                    if it['id'] not in returned_ids:
                        normalized.append({
                            'id': it['id'], 'category': it['category'], 'item': it['item'],
                            'compliance': 'æœªæåŠ', 'evidence': [], 'recommendation': ''
                        })
                all_results.extend(normalized)
        else:
            # é€é¡Œæ¨¡å¼ï¼ˆæ…¢ï¼‰
            items_ordered = order_items_AB_C_D_E(checklist_all)
            total_items = len(items_ordered)
            st.info("é€é¡Œæª¢æ ¸ä¸­")
            for i, it in enumerate(items_ordered):
                set_progress(35 + int((i/ max(1,total_items))*55), f"ğŸ§¾ ç¬¬ {i+1}/{total_items} é¡Œï¼š{it['id']} â€¦")
                prompt = make_single_prompt(it, corpus_text)
                try:
                    resp = model.generate_content(prompt)
                    arr = parse_json_array(resp.text)
                except Exception:
                    arr = []
                picked = None
                for d in arr if isinstance(arr, list) else []:
                    if isinstance(d, dict) and d.get('id') == it['id']:
                        picked = d; break
                if picked is None:
                    picked = {
                        'id': it['id'], 'category': it['category'], 'item': it['item'],
                        'compliance': 'æœªæåŠ', 'evidence': [], 'recommendation': ''
                    }
                else:
                    picked.setdefault('category', it['category'])
                    picked.setdefault('item', it['item'])
                    picked.setdefault('compliance', '')
                    picked.setdefault('evidence', [])
                    picked.setdefault('recommendation', '')
                all_results.append(picked)

        set_progress(92, "ğŸ“¦ å½™æ•´èˆ‡è½‰è¡¨æ ¼â€¦")
        df = to_dataframe(all_results)
        st.success("âœ… å¯©æŸ¥å®Œæˆ")
        render_wrapped_table(df, height_vh=80)

        # Excelï¼ˆè‡ªå‹•æ›è¡Œï¼‰
        try:
            from openpyxl.styles import Alignment
            xbio = io.BytesIO()
            with pd.ExcelWriter(xbio, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='æª¢æ ¸çµæœ')
                ws = writer.sheets['æª¢æ ¸çµæœ']
                for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
                    for cell in row:
                        cell.alignment = Alignment(wrap_text=True, vertical='top')
                for col_cells in ws.columns:
                    max_len = 12
                    for c in col_cells:
                        val = str(c.value) if c.value is not None else ''
                        max_len = max(max_len, min(80, len(val)))
                    ws.column_dimensions[col_cells[0].column_letter].width = min(60, max_len * 1.2)
            xbio.seek(0)
            st.download_button(
                label='ğŸ“¥ ä¸‹è¼‰ Excelï¼ˆè‡ªå‹•æ›è¡Œï¼‰',
                data=xbio.getvalue(),
                file_name=f"{project_name}_RFP_Contract_Checklist.xlsx",
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            )
        except Exception as e:
            st.warning(f"Excel åŒ¯å‡ºå¤±æ•—ï¼š{e}")

        progress_text.empty(); progress_bar.empty()

if __name__ == '__main__':
    main()
